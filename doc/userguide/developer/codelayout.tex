\section{Code Layout}
\label{sec:code:layout}

The PyLith software suite is composed of a C++ library, Python
modules, a Python application, and a few Python preprocessing and
post-processing utilities.

\subsection{Directory Structure}

\begin{description}
\item[\filename{applications}] Top-level Python application and
  utility drivers.
\item[\filename{libsrc}] C++ source for PyLith library.
\item[\filename{modulesrc}] SWIG interface files for C++ Python
  bindings.
\item[\filename{pylith}] Python source code for PyLith Python modules.
\item[\filename{doc}] Documentation.
\item[\filename{examples}] PyLith example suite.
\item[\filename{share}] Useful settings and configuration files.
\item[\filename{unittests}] Python and C++ unit tests source
  files. Run using \filename{make check}.
\item[\filename{tests\_auto}] Full-scale tests. Run using
  \filename{make check}.
\item[\filename{tests}] Full-scale tests that require manual checking
  of results.
\item[\filename{travis}] Helper scripts for building PyLith in
  Travis-CI.
\item[\filename{m4}] Autoconf macros (link to
  geodynamics/autoconfig Git repository).
\item[\filename{playpen}] Scratch area (obsolete). Use branches for
  scratch work instead.
\end{description}

We use the Pyre Python framework to collect all user parameters and to
launch the MPI application. As a result, the top-level code is written
in Python. In most cases there is a low-level C++ object of the same
name with the low-level implementation of the object. We limit the
Python code to collection of the user parameters, some simple
checking of the parameters, and passing the parameters to the
corresponding C++ objects.

The C++ library and Python modules are organized into several
subpackages.

\begin{description}
\item[\filename{bc}] Boundary conditions.
\item[\filename{faults}] Faults.
\item[\filename{feassemble}] General finite-element formulation.
\item[\filename{fekernels}] Finite-element point-wise functions (kernels).
\item[\filename{friction}] Fault constitutive models.
\item[\filename{materials}] Material behavior, including bulk constitutive models.
\item[\filename{meshio}] Input and output.
\item[\filename{problems}] General problem formulation.
\item[\filename{topology}] Finite-element mesh topology.
\item[\filename{utils}] General utilities.
\end{description}

\subsection{Build}

We strongly recommend using the PyLith Installer utility (see Section
\vref{sec:pylith:installer}) to build PyLith and its dependencies from
source.

\todo{Hackathon}{Hackathon participants should {\em first} build using
  the PyLith master branch. This corresponds to PyLith v2.2.1 with
  some very minor updates to keep the code in sync with
  PETSc. Configure the installer with
  \commandline{-{}-with-pylith-git=master}. See the \filename{INSTALL}
  file in the PyLith Installer source directory for additional
  instructions, including how to build in a separate directory from
  the source code. Those working on poroelasticity and infinite medium
  boundary condition (BIEM/FEM coupling) will be using different
  branches at the hackathon.}

\tip{ The PyLith Installer utility has the configure option
  \commandline{-{}-with-pylith-git=BRANCH} to specify which branch to
  use in the main Git repository.

  {\bf Added June 2018.} The PyLith Installer master branch
  has configure options to set the URL for the spatialdata
  (\commandline{-{}-with-spatialdata-repo}) and PyLith
  (\commandline{-{}-with-pylith-repo}) repositories.}

\tip{For all development, we build with debugging turned on. By
  building in directories separate from the source code, we can build
  an optimized version for production runs in a different directory and
  use environment variables to select the desired build.}

\subsubsection{Overview}

Pylith uses the GNU Build System (autotools: autoconf, automake,
libtool) to configure and build. The configure settings are defined in
\filename{configure.ac} with additional macros in the \filename{m4}
directory. Note that the \filename{m4} directory is a Git submodule
corresponding to the \filename{geodynamics/autoconf} Git repository.

The principal developers of PyLith use platform independent tools when
developing PyLith. The tools include Emacs and Atom.io for editing
source code, gdb and lldb for debugging, valgrind for checking for
memory errors, and gcov for examining code coverage of tests. We do
not use an integrated development environment (IDE) when developing
PyLith.

\subsubsection{Makefiles}

The PyLith \filename{configure} script uses automake to convert each
\filename{Makefile.am} file into a \filename{Makefile}. The
organization and content of the \filename{Makefile.am} file depends on
whether it is related to the C++ library, SWIG interface files, Python
modules, C++ unit tests, Python unit tests, or examples.

For the C++ library files within the \filename{libsrc} directory, the
\filename{libsrc/Makefile.am} contains the implementation files while
the header files are listed in the \filename{Makefile.am} file within
the underlying directories.

For the SWIG interface files within the \filename{modulesrc}
directory, the \filename{Makefile.am} file contains information on how
to build the SWIG Python module.

The Python modules use a single \filename{Makefile.am} file in
the \filename{pylith} directory.

Each test suite (C++ unit tests for each subpackage, Python unit tests
for each subpackage, and each suite of full-scale tests) use a single
\filename{Makefile.am}. These files define how the tests are built,
additional input files that should be included in the source
distribution, and temporary files that should be deleted.

Each suite of examples contains a \filename{Makefile.am} that defines
the files that are to be included in the source distribution. It also
defines which files are created and should be deleted upon
\commandline{make clean}.

\subsubsection{Build Targets}

Several build targets are defined to make it easy to rebuild/reinstall
PyLith rerun tests whenever the source code changes. Each target can
be run using \commandline{make TARGET} where \commandline{TARGET} is
one of the following:

\begin{description}
\item[all] Build.
\item[install] Build and install.
\item[check] Run all unit tests and full-scale automated tests.
\end{description}

\tip{On a machine with multiple cores, faster builds of the C++ code
  (library and C++ unit tests) are available using the
  \commandline{-jNTHREADS} command line argument, where
  \commandline{NTHREADS} is the number of cores to use. For example,
  \commandline{make -j16 all}.}

\subsection{PyLith Application Flow}

The PyLith application driver performs two main functions. First, it
collects all user parameters from input files (e.g., \filename{.cfg}
files) and the command line, and then it performs from simple checks
on the parameters. Second, it launches the MPI job.

Once the MPI job launches, the application flow is:
\begin{enumerate}
\item Read the finite-element mesh; \object{pylith.meshio.MeshImporter}.
  \begin{enumerate}
  \item Read the mesh (serial); \object{pylith::meshio::MeshIO}.
  \item Reorder the mesh; \object{pylith::topology::ReverseCuthillMcKee}.
  \item Insert cohesive cells as necessary (serial); \object{pylith::faults::FaultCohesive}.
  \item Distribute the mesh across processes (parallel); \object{pylith::topology::Distributor}.
  \item Refine the mesh if desired (parallel); \object{pylith::topology::RefineUniform}.
  \end{enumerate}
\item Setup the problem.
  \begin{enumerate}
  \item Preinitialize the problem by passing information from Python
    to C++ and doing minimal setup; \object{pylith.Problem.preinitialize()}.
  \item Perform consistency checks and additional checks of user
    parameters; \object{pylith.Problem.verifyConfiguration()}.
  \item Complete initialization of the problem;
    \object{pylith::problems::Problem::initialize()}.
  \end{enumerate}
\item Run the problem; \object{pylith.problems.Problem.run()}.
\item Cleanup; \object{pylith.problems.Problem.finalize()}.
  \begin{enumerate}
  \item Close output files.
  \item Deallocate memory.
  \item Output PETSc log summary, if desired.
  \end{enumerate}
\end{enumerate}

In the first step, we list the object performing the work, whereas in
subsequent steps we list the top-level object method responsible for
the work. Python objects are listed using the \object{path.class}
syntax while C++ objects are listed using \object{namespace::class}
syntax. Note that a child class may redefine or perform additional
work compared to what is listed in the parent class method.

Reading the mesh and the first two steps of the problem setup are
controlled from Python. That is, at each step Python calls the
corresponding C++ methods using SWIG. Starting with the complete
initialization of the problem, the flow is controlled at the C++
level.

\subsubsection{Time-Dependent Problem}

In a time-dependent problem, the PETSc \object{TS} object (relabeled
\object{PetscTS} within PyLith) controls the time stepping. At the
beginning of each time step, the \object{PetscTS} object calls
\object{problems::TimeDependent::prestep()}, and at the end of each
time step, it calls \object{problems::TimeDependent::poststep()}.

Within each time step, the \object{PetscTS} object calls the PETSc
linear and nonlinear solvers as needed, which call the following
methods of the C++ \object{pylith::problems::TimeDependent} object as
needed
\object{computeRHSResidual()},
\object{computeRHSJacobian()},
\object{computeLHSResidual()}, and
\object{computeLHSJacobian()}.

\section{PETSc Finite-Element Implementation}

Formulating the weak form of the governing equation in terms of
point-wise functions allows the PyLith implementation of the equations
to be done at a rather high level. Most of the finite-element details
are encapsulated in PETSc routines that compute the integrals and
solve the system of equations. In fact, adding materials and boundary
conditions rarely requires calling any PETSc finite-element
functions. Instead, a new material supplies and registers the
point-wise functions. The new material may need to add to the library
of solution subfields and auxiliary subfields, but adding these fields
is also done at a high-level.

The remainder of this section discusses three aspects of the
finite-element implementation handled by PyLith to give you a peek of
what is doing on under the hood.

\subsection{Meshing}

We have chosen to employ the \textit{cohesive element} formulation for faults, in order to apply separate constitutive
relations to the fault surface. Lets examine why we made this choice. We would like the two sides of the faults to
operate independently in some sense, but maintain a coupling (prescribed or dynamic). Thus we would like the
displacement of the two sides to be independent variables, constrained by the coupling equation. We could have
maintained the same mesh topology, but added extra variables on the vertices, edges, and faces on the fault
surface. However, this would change assembly on all cells along the fault, and greatly complicate optimization and
maintenance of the assembly code. So we pushed the complication to the mesh topology.

\subsection{\object{DMPlex}}

The finite-element mesh is stored as a \object{DMPlex} object. This is
a particular implementation of the PETSc Data Management (\object{DM},
renamed \object{PetscDM} within PyLith) object. Within a
\object{DMPlex} object vertices, edges, faces, and cells are all
called points. The points are numbered sequentially, beginning with
cells, followed by vertices, edges, and then faces. Treating all topological pieces of the mesh the same way, as points
in an abstract graph, allows us to write algorithms which apply to very different meshes without change. For example, we
can write a fintie element assembly loop that applies to meshes of any dimension, with any cell shape, with (almost) any
finite element.

\todo{brad}{Add diagram of finite-element mesh in DMPlex form.}

\subsection{\object{PetscSection} and \object{PetscVec}}

We store a field over the mesh in a vector (PETSc \object{Vec} object,
renamed \object{PetscVec} in PyLith). The \object{PetscSection} object
describes the layout of the vector over the DMPlex object. The vector
may hold multiple subfields, each with its own discretization. The
chart of the \object{PetscSection} defines the range of points
(minimum and maximum) over which the section is defined. For each
point in the chart, the section holds the number of degrees of freedom
it has and the offset in the \object{PetscVec} for its first degree of
freedom. The section also holds the number of degrees of freedom and
offset for each individual subfield within the section.

Because the \object{PetscSection} knows only about points, and not about topolgoy or geometry, it allows us to express
the mathematical concepts without getting lost in the details. For example, a $P_1$ 3D vector field assigns 3 dofs to
each vertex. This same section could be used to layout a field over a circle, surface of a cylinder, M\"obius strip,
sphere, cube, ball, or Pylith mesh. It separates the layout of data over a mesh from the actual storage of values, which
is done by a plain old PETSc \object{Vec}. The section tells you how to look up the values, which are ``attached'' to a
piece of the mesh, inside the vector. For example, you can ask for the offset into the vector for the values associated
with an edge in the mesh, and how many dofs there are on the edge.

The \object{PetscSection} also includes the information about the
constrained degrees of freedom. We refer to the \object{PetscVec} with
the constrained degrees of freedom included as the {\em local} vector
and the \object{PetscVec} with the constrained degrees of freedom
removed as the {\em global} vector. Constraints often arise from Dirichlet boundary conditions, which change directly
the basis functions of the approximating space, but can also arise from algebraic relations between unknowns. A local
vector is often used for assembly of the residual vector and Jacobian matrix, since we need the boundary values in order
to compute those integrals. Whereas global vectors are used for the algebraic solver since we do not want unknowns fixed
by constraints to participate in the solve.

\todo{brad}{Add ASCII view of PetscSection corresponding to
  finite-element mesh.}

\subsection{Integration}

Integration involves integrals over the domain or the boundary of the
domain. These two operations are done by different PETSc functions.

\begin{description}
\item[\object{DMPlexComputeResidual\_Internal}] Compute the
  contribution to the LHS or RHS residual for a single material. This
  function and the functions it calls handle looping over the cells in
  the material, integrating the weak form for each of the fields, and
  adding them to the residual.

  A more appropriate name would be
  \object{DMPlexComputeResidualSingle} although that may change once
  we have a separate \object{PetscDM} for each material.
%
\item[\object{DMPlexComputeBdResidualSingle}] Compute the contribution
  to the LHS or RHS residual for a single boundary condition. This
  function and the functions it calls handle looping over the
  boundary, integrating the weak form for each of the fields, and
  adding them to the residual.
\end{description}

\subsection{Projection}

Input and output often involve projecting fields to/from the finite-element space. PETSc provides a family of functions
for this. We generally use two of these, one for analytical functions and one for discretized fields. Projection may be
a misleading term here, since we are not refering to the common $L_2$ projection, but rather interpolation of the
function by functions in our finite element space.

How do we find the interpolant? Lets start with the simple example of Fourier analysis, which most people have
experience with. If I want the Fourier interpolant $\tilde f$ for a given function $f$, then I need to determine its
Fourier coefficients,
\begin{align}
  \tilde f = \sum_k f_k e^{i k x}.
\end{align}
This is not difficult because the basis functions in the Fourier representation are orthogonal
\begin{align}
  \int^{2\pi}_0 e^{-i m x} e^{i k x} = 2\pi \delta_{km}.
\end{align}
Thus, we just multiply by the conjugate of the basis function and integrate,
\begin{align}
  \int^{2\pi}_0 e^{-i m x} \tilde f &= \int^{2\pi}_0 e^{-i m x} \sum_k f_k e^{i k x}, \\
                                  &= \sum_k f_k \int^{2\pi}_0 e^{-i m x} e^{i k x}, \\
                                  &= \sum_k f_k 2\pi \delta_{km}, \\
                                  &= 2\pi f_m, \\
\end{align}
and we have our coefficient $f_m$. The finite element basis $\{\phi_i\}$ is not orthogonal, so we have an extra step. We
could take the inner product of $f$ with all the basis functions, and then sort out the dependecies by solving a linear
system (the mass matrix), which is what happens in $L_2$ projection. However, suppose we have another basis $\{\psi_i\}$
of linear functionals which is \textit{biorthogonal} to $\{\phi_i\}$, meaning
\begin{align}
  \psi_i(\phi_j) = \delta_{ij}.
\end{align}
Then we can easily pick out the coefficient of $\tilde f$ by acting with the corresponding basis functional,
\begin{align}
  \tilde f &= \sum_k f_k \phi_k(x),\\
  \psi_i(\tilde f) &= \psi_i(\sum_k f_k \phi_k(x)),\\
  \psi_i(\tilde f) &= \sum_k f_k \psi_i(\phi_k(x)),\\
  \psi_i(\tilde f) &= \sum_k f_k \delta_{ik},\\
  \psi_i(\tilde f) &= f_i,\\
\end{align}
where we used the linearity of the $\psi_i$ in the third step. We will call $\{\phi_i\}$ the \textit{primal} basis, and
$\{\psi_i\}$ the \textit{dual} basis. We note that if $f$ does not lie in our approximation space spanned by
$\{\phi_i\}$, then interpolation is not equivalent to $L_2$ projection. This will not usually be important for our
purposes.

\begin{description}
\item[\object{DMProjectFunctionLocal}] Project an analytical function
  into the given finite-element space.
\item[\object{DMProjectFieldLocal}] Project a discretized field in one
  finite-element space into another finite-element space.
\end{description}


\section{Adding New Governing Equations and/or Materials}

There are four basic pieces to adding new physics in the form of a
governing equation or material:
\begin{enumerate}
\item Select the fields for the solution. This will control the form
  of the partial differential equation and the terms in the residuals
  and Jacobians.
\item Derive the point-wise functions for the residuals and
  Jacobians. Determine what flags will be used to indicate which terms
  to include.
\item Determine which parameters in the point-wise functions could
  vary in space as well as any state variables. We bundle all state variables
  and spatially varying parameters into a field called the auxiliary
  field. Each material has a separate auxiliary field.
\item Parameters that are spatially uniform and constant in time
  are treated separately from the parameters in the auxliary field.
\end{enumerate}

\subsection{Python}

\begin{itemize}
\item Define solution subfields.

  \begin{itemize}
  \item All subfields in the solution field are \object{SolutionSubfield}
    objects. PyLith already includes several solution subfields:
    \begin{description}
    \item[\object{SubfieldDisplacement}] Displacement vector field.
    \item[\object{SubfieldVelocity}] Velocity vector field.
    \item[\object{SubfieldLagrangeFault}] Lagrange multiplier field for
      fault constraints.
    \item[\object{SubfieldPressure}] Fluid pressure or mean stress scalar field.
    \item[\object{SubfieldTemperature}] Temperature scalar field.
    \end{description}
    %
  \item PyLith includes solution field containers with predefined
    subfields:
    \begin{description}
    \item[\object{SolnDisp}] Solution composed of a displacement field.
    \item[\object{SolnDispVel}] Solution composed of displacement and velocity fields.
    \item[\object{SolnDispPres}] Solution composed of displacement and
      mean stress (pressure) fields.
    \item[\object{SolnDispLagrange}] Solution composed of displacement
      and Lagrange multiplier fields.
    \item[\object{SolnDispPresLagrange}] Solution composed of
      displacement, mean stress (pressure), and Lagrange multiplier subfields.
    \item[\object{SolnDispVelLagrange}] Solution composed of
      displacement, velocity, and Lagrange multiplier subfields.
    \end{description}
  \end{itemize}
%
\item Define auxiliary subfields.

  The auxiliary subfields for a material are defined as facilities in
  a Pyre Component. For example, the ones for
  \object{IsotropicLinearElasticityPlaneStrain} are in
  \object{AuxFieldIsotropicLinearElasticity}. The order of the subfields
  is defined {\em not} by the order they are listed in the Pyre
  component, but by the order they are added to the auxiliary field in
  by the C++ object. 

\item Flags to turn on/off terms in governing equation.

  For the elasticity equation, we sometimes do not include body forces
  or inertial terms in our simulations. Rather than implement these
  cases as separate materials, we simply include flags in the material
  to turn these terms on/off. The flags are implemented as Pyre
  properties in our material component.
\end{itemize}

\todo{brad}{Add class diagram showing relationships among
  \object{Solution}, \object{SolnDisp}, \ldots,
  \object{SolutionSubfield}, \object{SubfieldDisplacement}, \ldots}

\subsection{C++}

\warning{We will likely be refactoring the \object{Material} and
  \object{IntegratorPointwise}, so how the point-wise functions for
  the residual, Jacobians, state variable update, and computation of
  derived fields are set will likely be significantly different and
  easier in the future. For now, you should use
  \object{IsotropicLinearElasticityPlaneStrain} as a model for how to
  implement a material.}

\begin{itemize}
\item Define auxiliary subfields.

  We build the auxiliary field using classes derived from
  \object{pylith::feassemble::AuxiliaryFactory}. The method
  corresponding to each subfield specifies the name of the subfield,
  its components, and scale for nondimensionalizing. We generally
  create a single auxiliary factor object for each governing equation
  but not each bulkd constitutive model, because constitutive models
  for the same governing equation often have many of the same
  subfields. For example, most of our bulk constitutive models for the
  elasticity contain density, bulk modulus, and shear modulus
  auxiliary subfields.

  \important{Within the concrete implementation of the material
    object, we add the subfields to the auxiliary field. The order in
    which they are added determines the order they will be in the
    auxiliary field. You will need to use know this order when you
    implement the point-wise functions.}

\item Implement the point-wise functions.

  The point-wise functions for the residuals, Jacobians, and
  projections follow nearly identical interfaces. Note that within
  PyLith, we use PylithInt, PylithReal, and PylithScalar instead of
  PetscInt, PetscReal, and PetscScalar.

\item Set the point-wise functions.

  We set the point-wise functions for the residual using
  \object{PetscDSSetResidual} and for the Jacobian using
  \object{PetscDSSetJacobian}.
  
\end{itemize}

\begin{cplusplus}[PetscPointFunc Interface]
/** Interface for PETSc point-wise functions.
 *
 * @param[in] dim Spatial dimension of problem.
 * @param[in] Nf Number of subfields in the field.
 * @param[in] NfAux Number of subfields in the auxiliary field.
 * @param[in] uOff Offset into u and u_t[] for each subfield.
 * @param[in] uOff_x Offset into u_x for each subfield.
 * @param[in] u Values of each subfield at the current point.
 * @param[in] u_t Time derivative of each subfield at the current point.
 * @param[in] u_x Gradient of each subfield at the current point.
 * @param[in] aOff Offset into u and u_t[] for each auxiliary subfield.
 * @param[in] aOff_x Offset into u_x for each auxiliary subfield.
 * @param[in] a Values of each auxiiliary subfield at the current point.
 * @param[in] a_t Time derivative of each auxiliary subfield at the current point.
 * @param[in] a_x Gradient of each auxiliary subfield at the current point.
 * @param[in t Current time.
 * @param[in] x Coordinates of current point.
 * @param[in] numConstants Number of constant parameters.
 * @param[in] constants Constant parameters.
 * @param[out] f Output values at current point.
 */
 void
 func(PetscInt dim,
      PetscInt Nf,
      PetscInt NfAux,
      const PetscInt uOff[],
      const PetscInt uOff_x[],
      const PetscScalar u[],
      const PetscScalar u_t[],
      const PetscScalar u_x[],
      const PetscInt aOff[],
      const PetscInt aOff_x[],
      const PetscScalar a[],
      const PetscScalar a_t[],
      const PetscScalar a_x[],
      PetscReal t,
      const PetscReal x[],
      PetscScalar f0[]);
\end{cplusplus}
  
\begin{cplusplus}[PetscPointJac Interface]
/** Interface for PETSc point-wise Jacobians.
 *
 * This is identical to the PetscPointFunc with the addition of the
 * u_tShift argument.
 *
 * @param[in] u_tShift The multiplier for dF/dU_t.
 */
 void
 func(PetscInt dim,
      PetscInt Nf,
      PetscInt NfAux,
      const PetscInt uOff[],
      const PetscInt uOff_x[],
      const PetscScalar u[],
      const PetscScalar u_t[],
      const PetscScalar u_x[],
      const PetscInt aOff[],
      const PetscInt aOff_x[],
      const PetscScalar a[],
      const PetscScalar a_t[],
      const PetscScalar a_x[],
      PetscReal t,
      PetscReal u_tShift,
      const PetscReal x[],
      PetscScalar Jf0[]);
\end{cplusplus}
  
\begin{cplusplus}[PetscDSSetResidual Function]
/** Set point-wise functions for LHS or RHS residual.
 *
 * @param[in] prob PetscDS associated with solution field.
 * @param[in] f Index of solution subfield for residual term.
 * @param[in] f0 Point-wise function for f0/g0 term in weak form.
 * @param[in] f1 Point-wise function for f1/g1 term in weak form.
 *
 * @returns PETSc error code (0 indicates no errors).
 */
 PetscErrorCode
 PetscDSSetResidual(PetscDS prob,
                    PetscInt f,
                    PetscPointFunc f0,
                    PetscPointFunc f1);
\end{cplusplus}
  
\begin{cplusplus}[PetscDSSetJacobian Function]
/** Set point-wise functions for LHS or RHS Jacobian.
 *
 * @param[in] prob PetscDS associated with solution field.
 * @param[in] f Index of trial subfield for Jacobian term.
 * @param[in] g Index of field subfield for Jacobian term.
 * @param[in] Jf0 Point-wise function for Jf0/Jg0 term in weak form.
 * @param[in] Jf1 Point-wise function for Jf1/Jg1 term in weak form.
 * @param[in] Jf2 Point-wise function for Jf2/Jg2 term in weak form.
 * @param[in] Jf3 Point-wise function for Jf3/Jg3 term in weak form.
 *
 * @returns PETSc error code (0 indicates no errors).
 */
 PetscErrorCode
 PetscDSSetResidual(PetscDS prob,
                    PetscInt f,
                    PetscInt g,
                    PetscPointJac Jf0,
                    PetscPointJac Jf1,
                    PetscPointJac Jf2,
                    PetscPointJac Jf3);
\end{cplusplus}
  
\todo{brad}{Add class diagram showing relationships among
  \object{Material}, \object{ConcreteMaterialA}, \ldots,
  \object{Integrator}, \object{IntegratorSubdomain}, \ldots}

\subsection{C++ Unit Tests}

\todo{brad}{Layout of unit tests. Method of manufactured
  solutions. Use of \object{UserFunctionDB} spatial database.}

\todo{brad}{Add class diagram showing relationships among
  \object{TestMaterial}, \object{TestConcreteMaterialA}, \ldots,
  \object{TestConcreteMaterialA\_Data}, \object{TestConcreteMaterialA\_MMS}, \ldots}


\subsection{Python Unit Tests}

\todo{brad}{Goal of Python unit tests.}

\section{Adding New Boundary Conditions}



\todo{brad}{Complete this section before the hackathon.}

\begin{itemize}
\item Pointwise functions
\item Auxiliary subfields
\end{itemize}

\subsection{Python}

\begin{itemize}
\item Define auxiliary subfields
\item Flags to turn on/off terms.
\end{itemize}

\subsection{C++}

\begin{itemize}
\item IntegratorPointwise or ConstraintPointwise methods
\item Setting pointwise functions for residual, Jacobian, updating
  state variables, and calculating derived fields.
\item Setting up auxiliary subfields.
\end{itemize}

\subsection{C++ Unit Tests}

\subsection{Python Unit Tests}


\section{Adding Support for New Mesh File Formats}

\brad{Future: Add stuff here.}
